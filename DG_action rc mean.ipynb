{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "import dynamo as dyn\n",
    "import numpy as np\n",
    "from anndata import AnnData\n",
    "# import loompy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from scipy.cluster.hierarchy import fcluster,leaders\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import inv\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.sparse import csr_matrix,issparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.csgraph\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.model_selection as skms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from ignite.engine import Engine, Events\n",
    "#from ignite.handlers import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, IterableDataset, get_worker_info\n",
    "\n",
    "CHECKPOINT_PREFIX = \"g2g\"\n",
    "\n",
    "from utils import *\n",
    "# from minepy import MINE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "method = ''\n",
    "from g2g_model_Fisher import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data overview** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "data_name = 'DG_bin_ppt'\n",
    "# data_name = 'DG_new'\n",
    "# data_name = 'A549_emt_bin'\n",
    "# data_name = 'zebrafish_dynamo_part'\n",
    "# data_name = 'neural_bin'\n",
    "# adata0 = scv.read(data_path+data_name+'.h5ad', cache=True)\n",
    "adata0 = scv.read(data_path+data_name+'.h5ad', cache=True)\n",
    "\n",
    "# [k_nei, K] = [10, 4]\n",
    "# L = np.load('results/'+data_name+','+method+'/'+str([k_nei,K])+',latent_dim.npy')\n",
    "pca_dim = 50\n",
    "[k_nei, K, L] = [10, 2, 10]\n",
    "# metric = 'minkowski'\n",
    "metric = 'euclidean'\n",
    "# metric = 'cosine'\n",
    "# metric = 'correlation'\n",
    "norm = 'none'\n",
    "# norm = 'standard'\n",
    "# norm = 'minmax'\n",
    "\n",
    "result_path = 'rc_action_results/'+data_name+','+norm+','+metric+','+method+','+str([k_nei,K,L])+'/'\n",
    "figure_path = result_path\n",
    "cmap = plt.colormaps['Spectral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = os.path.exists(result_path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(result_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "\n",
    "folder = os.path.exists(figure_path)\n",
    "if not folder:\n",
    "    os.makedirs(figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scanpy as sc\n",
    "adata = adata0.copy()\n",
    "sc.pp.pca(adata, n_comps=pca_dim)\n",
    "sc.pp.neighbors(adata, n_neighbors=k_nei)\n",
    "scv.pp.moments(adata, n_pcs=pca_dim, n_neighbors=k_nei)\n",
    "scv.tl.velocity(adata)\n",
    "\n",
    "gene_arr = adata.var.index.values\n",
    "X_pca = adata.obsm['X_pca']\n",
    "X_umap = adata.obsm['X_umap']\n",
    "Xs = adata.layers['Ms'] #adata.X.A#\n",
    "# Xs = adata.layers['M_s'] #如果是EG_ab_dyn\n",
    "X = Xs\n",
    "\n",
    "row = np.array([np.ones((k_nei,))*i for i in range(adata.shape[0])]).flatten()\n",
    "col = (adata.obsp['distances']+csr_matrix(np.eye(adata.obsp['distances'].shape[0]))).indices\n",
    "w_val = np.array([np.linalg.norm(X_pca[int(i),:]-X_pca[int(j),:]) for i,j in zip(row,col)])\n",
    "adj_val = np.ones(col.shape)\n",
    "A_mat = csr_matrix((adj_val, (row, col)), shape=(adata.shape[0], adata.shape[0]))\n",
    "W_mat = csr_matrix((w_val, (row, col)), shape=(adata.shape[0], adata.shape[0]))\n",
    "\n",
    "dc=np.amax(adata.obsp['distances'])\n",
    "cell_nei=adata.obsp['distances'].indices.reshape([-1,k_nei-1])\n",
    "nei_w=[]\n",
    "rho_arr=[]\n",
    "for i in range(cell_nei.shape[0]):\n",
    "    dij=np.array([np.linalg.norm(X_pca[i,:]-X_pca[int(j),:]) for j in cell_nei[i]])\n",
    "    \n",
    "    rho=np.sum(np.exp(-dij**2/dc**2))\n",
    "    nei_w.append(np.exp(-dij**2/dc**2)/rho)\n",
    "    rho_arr.append(rho)\n",
    "rho_arr=np.array(rho_arr)/np.amax(rho_arr)\n",
    "nei_w=np.array(nei_w)\n",
    "\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "encoder = torch.load(result_path+'encoder.pt')\n",
    "\n",
    "\n",
    "mu, sigma = encoder(torch.tensor(X))\n",
    "mu_learned = mu.detach().numpy()\n",
    "sigma_learned = sigma.detach().numpy()\n",
    "\n",
    "Fisher_g=np.zeros((X.shape[0],L*2,L*2))\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(L):\n",
    "        Fisher_g[i,j,j]=1/sigma_learned[i,j]**2\n",
    "        Fisher_g[i,L+j,L+j]=2/sigma_learned[i,j]**2\n",
    "\n",
    "Fisher_g_diag = np.zeros([X.shape[0],L*2])\n",
    "for i in range(X.shape[0]):\n",
    "    Fisher_g_diag[i] = np.diag(Fisher_g[i])\n",
    "\n",
    "def smooth_func(X_val,cell_nei=cell_nei,nei_w=nei_w):\n",
    "    X_s=X_val.copy()\n",
    "    for ci in range(len(X_val)):\n",
    "        X_s[ci]=np.dot(X_val[cell_nei[ci,:]],nei_w[ci,:])\n",
    "    return(X_s)\n",
    "\n",
    "def wasserstein_distance(mu1,sigma1,mu2,sigma2):\n",
    "    dim=len(mu1)\n",
    "    dmu=mu1-mu2\n",
    "    W_dist2=0\n",
    "    for i in range(dim):\n",
    "        W_dist2+=dmu[i]**2+sigma1[i]**2+sigma2[i]**2-2*np.sqrt(sigma2[i]*sigma1[i]**2*sigma2[i])\n",
    "    W_dist=np.sqrt(W_dist2+1e-12)\n",
    "    return W_dist\n",
    "\n",
    "cRc_arr=[]\n",
    "cRc_arr_eu=[]\n",
    "A = csr_matrix(A_mat + np.eye(A_mat.shape[0]))\n",
    "for inds in np.split(A.indices, A.indptr)[1:-1]:\n",
    "    self_ind=inds[0]\n",
    "    cRc=0\n",
    "    cRc_eu=0\n",
    "    for nei_k in range(1,len(inds)):\n",
    "\n",
    "        dEu=np.linalg.norm(X[self_ind,:]-X[inds[nei_k],:])\n",
    "        dFi=Fisher_dist(mu_learned[self_ind,:],sigma_learned[self_ind,:],\\\n",
    "                        mu_learned[inds[nei_k],:],sigma_learned[inds[nei_k],:])\n",
    "        dWa=wasserstein_distance(mu_learned[self_ind,:],sigma_learned[self_ind,:],\\\n",
    "                        mu_learned[inds[nei_k],:],sigma_learned[inds[nei_k],:])\n",
    "\n",
    "        cRc+=1-dWa/dFi\n",
    "        cRc_eu+=1-dWa/dEu\n",
    "\n",
    "    cRc_arr.append(cRc/len(inds))\n",
    "    cRc_arr_eu.append(cRc_eu/len(inds))\n",
    "crc = np.array(cRc_arr)\n",
    "crc_eu = np.array(cRc_arr_eu)\n",
    "crc_smooth = smooth_func(crc_eu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo0 = np.array(adata.layers['velocity'])\n",
    "velo_g = np.zeros(velo0.shape)\n",
    "velo_g[:,adata.var['velocity_genes']] = velo0[:,adata.var['velocity_genes']]\n",
    "velo_pca = velo_g@adata.varm['PCs']\n",
    "latent_z = np.hstack((mu_learned,sigma_learned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plt = -X_pca[:,0]\n",
    "Y_plt = -X_pca[:,1]\n",
    "X_min = np.min(X_plt)\n",
    "X_max = np.max(X_plt)\n",
    "Y_min = np.min(Y_plt)\n",
    "Y_max = np.max(Y_plt)\n",
    "X_len = (X_max-X_min)/5\n",
    "Y_len = (Y_max-Y_min)/5\n",
    "wid = min(X_len,Y_len)/30\n",
    "X_ori = X_min-wid*10\n",
    "Y_ori = Y_min-wid*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ~np.isnan(crc_smooth)\n",
    "cmap = plt.colormaps['Spectral']\n",
    "plt.scatter(X_plt[idx],Y_plt[idx],c=crc_smooth[idx],s=30,cmap=cmap)\n",
    "plt.axis('off')\n",
    "clb=plt.colorbar()\n",
    "clb.ax.set_ylabel('curvature',fontsize=20,weight='bold')\n",
    "clb.ax.tick_params(axis='y', labelsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Average Path** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_path = np.load(result_path+'EG_dyn_rc.npy')\n",
    "# average_path = np.load(result_path+'average_path.npy')\n",
    "average_path[:, 1] = -average_path[:, 1]\n",
    "# Plotting the average path\n",
    "idx = ~np.isnan(crc_smooth)\n",
    "cmap = plt.colormaps['Spectral']\n",
    "plt.scatter(X_plt[idx],Y_plt[idx],c=crc_smooth[idx],s=30,cmap=cmap)\n",
    "clb=plt.colorbar()\n",
    "clb.ax.set_ylabel('curvature',fontsize=20,weight='bold')\n",
    "clb.ax.tick_params(axis='y', labelsize=15)\n",
    "# plt.savefig(figure_path+'5c1.png',dpi=600,bbox_inches='tight')\n",
    "plt.axis('off')\n",
    "plt.scatter(-average_path[:,0],-average_path[:,1],c='purple', linewidth=2, label='RC path')\n",
    "plt.scatter(-average_path[0,0],-average_path[0,1],c='red', linewidth=2, label='Start')\n",
    "plt.scatter(-average_path[-1,0],-average_path[-1,1],c='blue', linewidth=2, label='End')\n",
    "# plt.scatter(X_plt[average_path[0]],Y_plt[average_path[0]], color='red', s=50, label='Start')\n",
    "# plt.scatter(X_plt[average_path[-1]],Y_plt[average_path[-1]], color='blue', s=50, label='End')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "\n",
    "\n",
    "plt.arrow(X_ori-wid/2,Y_ori,X_len,0,width=wid,color='black',head_width=5*wid)\n",
    "plt.arrow(X_ori,Y_ori-wid/2,0,Y_len,width=wid,color='black',head_width=5*wid)\n",
    "plt.text(X_ori+X_len/2,Y_ori-wid*14,'$UMAP_1$',fontsize=14,ha='center',weight='bold')\n",
    "plt.text(X_ori-wid*25,Y_ori+Y_len/2,'$UMAP_2$',fontsize=14,ha='center',weight='bold')\n",
    "\n",
    "plt.savefig(result_path+'path.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trans coordinates in average_path to nodes indices\n",
    "# distances = np.linalg.norm(X_pca[:, np.newaxis,:] - average_path, axis=2)\n",
    "\n",
    "# nearest_indices = np.argmin(distances, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For each cell, find its nearest reaction coordinate** ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans coordinates in average_path to nodes indices\n",
    "# trans coordinates in average_path to nodes indices\n",
    "distances = np.linalg.norm(X_pca[:, np.newaxis,:10] - average_path[:,:10], axis=2)\n",
    "\n",
    "nearest_indices = np.argmin(distances, axis=0)\n",
    "\n",
    "cell_arr = [[] for i in range(average_path.shape[0])]\n",
    "for j in range(adata.shape[0]):\n",
    "    distances = np.linalg.norm(X_pca[j,:10] - average_path, axis=1)\n",
    "    reaction_coordinate = np.argmin(distances, axis=0)\n",
    "    cell_arr[reaction_coordinate].append(j)\n",
    "\n",
    "for i in range(len(cell_arr)):\n",
    "    cell_arr[i] = np.array(cell_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~(np.array([len(cell_arr[i]) for i in range(len(cell_arr))]) == 0)\n",
    "average_path = average_path[mask,:]\n",
    "nearest_indices = nearest_indices[mask]\n",
    "\n",
    "cell_arr = [[] for i in range(average_path.shape[0])]\n",
    "for j in range(adata.shape[0]):\n",
    "    distances = np.linalg.norm(X_pca[j,:10] - average_path, axis=1)\n",
    "    reaction_coordinate = np.argmin(distances, axis=0)\n",
    "    cell_arr[reaction_coordinate].append(j)\n",
    "\n",
    "for i in range(len(cell_arr)):\n",
    "    cell_arr[i] = np.array(cell_arr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# average_path = np.load(result_path+'average_path.npy')\n",
    "# average_path[:, 1] = -average_path[:, 1]\n",
    "# Plotting the average path\n",
    "idx = ~np.isnan(crc_smooth)\n",
    "cmap = plt.colormaps['Spectral']\n",
    "plt.scatter(X_plt[idx],Y_plt[idx],c=crc_smooth[idx],s=30,cmap=cmap)\n",
    "clb=plt.colorbar()\n",
    "clb.ax.set_ylabel('curvature',fontsize=20,weight='bold')\n",
    "clb.ax.tick_params(axis='y', labelsize=15)\n",
    "# plt.savefig(figure_path+'5c1.png',dpi=600,bbox_inches='tight')\n",
    "plt.axis('off')\n",
    "plt.scatter(-average_path[:,0],-average_path[:,1],c='purple', linewidth=2, label='RC path')\n",
    "plt.scatter(-average_path[0,0],-average_path[0,1],c='red', linewidth=2, label='Start')\n",
    "plt.scatter(-average_path[-1,0],-average_path[-1,1],c='blue', linewidth=2, label='End')\n",
    "# plt.scatter(X_plt[average_path[0]],Y_plt[average_path[0]], color='red', s=50, label='Start')\n",
    "# plt.scatter(X_plt[average_path[-1]],Y_plt[average_path[-1]], color='blue', s=50, label='End')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "\n",
    "\n",
    "plt.arrow(X_ori-wid/2,Y_ori,X_len,0,width=wid,color='black',head_width=5*wid)\n",
    "plt.arrow(X_ori,Y_ori-wid/2,0,Y_len,width=wid,color='black',head_width=5*wid)\n",
    "plt.text(X_ori+X_len/2,Y_ori-wid*14,'$UMAP_1$',fontsize=14,ha='center',weight='bold')\n",
    "plt.text(X_ori-wid*25,Y_ori+Y_len/2,'$UMAP_2$',fontsize=14,ha='center',weight='bold')\n",
    "\n",
    "plt.savefig(result_path+'path.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ~np.isnan(crc_smooth)\n",
    "cmap = plt.colormaps['Spectral']\n",
    "plt.scatter(X_plt[idx],Y_plt[idx],c=crc_smooth[idx],s=30,cmap=cmap)\n",
    "clb=plt.colorbar()\n",
    "clb.ax.set_ylabel('curvature',fontsize=20,weight='bold')\n",
    "clb.ax.tick_params(axis='y', labelsize=15)\n",
    "# plt.savefig(figure_path+'5c1.png',dpi=600,bbox_inches='tight')\n",
    "plt.axis('off')\n",
    "plt.scatter(-average_path[:,0],-average_path[:,1],c='purple', linewidth=2, label='RC path')\n",
    "plt.scatter(-average_path[0,0],-average_path[0,1],c='red', linewidth=2, label='Start')\n",
    "plt.scatter(-average_path[-1,0],-average_path[-1,1],c='blue', linewidth=2, label='End')\n",
    "# plt.scatter(X_plt[average_path[0]],Y_plt[average_path[0]], color='red', s=50, label='Start')\n",
    "# plt.scatter(X_plt[average_path[-1]],Y_plt[average_path[-1]], color='blue', s=50, label='End')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "\n",
    "\n",
    "plt.arrow(X_ori-wid/2,Y_ori,X_len,0,width=wid,color='black',head_width=5*wid)\n",
    "plt.arrow(X_ori,Y_ori-wid/2,0,Y_len,width=wid,color='black',head_width=5*wid)\n",
    "plt.text(X_ori+X_len/2,Y_ori-wid*14,'$UMAP_1$',fontsize=14,ha='center',weight='bold')\n",
    "plt.text(X_ori-wid*25,Y_ori+Y_len/2,'$UMAP_2$',fontsize=14,ha='center',weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot the FI and Velo along the path** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------use a simple neural network to study dmu/dt and dsigma/dt\n",
    "latent_z = np.hstack((mu_learned,sigma_learned))\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(pca_dim, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,2*L),\n",
    ")\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "x_in=torch.tensor(X_pca.astype(np.float32))\n",
    "x_out=torch.tensor(latent_z.astype(np.float32))\n",
    "# Train the model\n",
    "for epoch in range(200):  # number of epochs\n",
    "    # Forward pass\n",
    "    output = model(x_in)\n",
    "    loss = loss_fn(output,x_out) \n",
    "#     if epoch% 10 == 9:\n",
    "#         print(epoch,loss)\n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "pZ_pX = np.zeros([X.shape[0], L*2, X_pca.shape[1]])\n",
    "\n",
    "# Compute the gradients\n",
    "for i in range(X.shape[0]):\n",
    "    x0=torch.tensor(X_pca[i,:],requires_grad=True)\n",
    "    z=model(x0)\n",
    "    for j in range(2*L):\n",
    "        x0.grad = None       \n",
    "        z[j].backward(retain_graph=True)\n",
    "        pZ_pX[i,j,:] = x0.grad.detach()\n",
    "        \n",
    "Fisher_pca = np.zeros((X.shape[0],pca_dim, pca_dim))\n",
    "for i in range(X.shape[0]):\n",
    "    Fisher_pca[i] = pZ_pX[i].T@Fisher_g[i]@pZ_pX[i]\n",
    "\n",
    "Z_velo = np.array([pZ_pX[i]@velo_pca[i] for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_pro = Z_velo\n",
    "alpha = 0.3\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(L):\n",
    "    Fisher_g_path = np.array([np.mean(smooth_func(Fisher_g[:,i,i])[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.mean(smooth_func(np.abs(velo_pro[:,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "\n",
    "    # plt.plot(range(len(cell_arr)), Fisher_g_path, label='Fisher', c=palette1[0])\n",
    "\n",
    "\n",
    "    # plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    # plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    # plt.xticks(fontsize=15)\n",
    "    # plt.yticks(fontsize=15)\n",
    "\n",
    "    # ymin1 = min(Fisher_g_path)\n",
    "    # ymax1 = max(Fisher_g_path)\n",
    "    # plt.ylim(ymin1,ymax1)\n",
    "\n",
    "    # plt.twinx()\n",
    "    # plt.plot(range(len(cell_arr)), velo_pro_g_path, label='Velo', c=palette1[1])\n",
    "    # plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    # plt.yticks(fontsize=15)\n",
    "    \n",
    "    # ymin2 = min(velo_pro_g_path)\n",
    "    # ymax2 = max(velo_pro_g_path)\n",
    "    # plt.ylim(ymin2,ymax2)\n",
    "    \n",
    "   \n",
    "\n",
    "    # ax = plt.gca()\n",
    "    # ax.spines['left'].set_color(palette1[0])\n",
    "    # ax.spines['right'].set_color(palette1[1])\n",
    "    # ax.spines['left'].set_linewidth(3)\n",
    "    # ax.spines['right'].set_linewidth(3)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), Fisher_g_path, s=0.01)  \n",
    "    x_ls1 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls1 = spline(x_ls1)\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette2[0],s=10,alpha=alpha)\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), velo_pro_g_path, s=0, k=1)  \n",
    "    x_ls2 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls2 = spline(x_ls1)\n",
    "\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    ymin1 = min(y_ls1)\n",
    "    ymin1 = max([ymin1,0])\n",
    "    ymax1 = max(y_ls1)\n",
    "    plt.ylim(0,0.05)\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette2[1],s=10,alpha=alpha)\n",
    "    plt.yticks([])\n",
    "    ymin2 = min(y_ls2)\n",
    "    ymin2 = max([ymin2,0])\n",
    "    ymax2 = max(y_ls2)\n",
    "    plt.ylim(0,0.2)\n",
    "\n",
    "    plt.twinx()\n",
    "    ln1 = plt.plot(x_ls1, y_ls1, linewidth=4,color=palette1[0],label='$FI$')\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,0.05)\n",
    "\n",
    "    plt.twinx()\n",
    "    # # ln3 = plt.plot(x_ls3, y_ls3, linewidth=4,color=palette1[1],label='$g_{'+str(ei)+str(ej)+'}$')\n",
    "    ln2 = plt.plot(x_ls2, y_ls2, linewidth=4,color=palette1[1],label='$Velo$')\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(0,0.2)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_action{i}.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **plot on eigengene** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = adata.layers['Ms']#adata.X.A#\n",
    "Xu = adata.layers['Mu']\n",
    "scaler = StandardScaler()#MinMaxScaler()#\n",
    "X = scaler.fit_transform(Xs)\n",
    "\n",
    "X_corr=np.corrcoef(X, rowvar=False)\n",
    "plt.imshow(X_corr)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "Z=linkage((1-X_corr)[np.triu_indices(X_corr.shape[0],k=1)],method='weighted')#method='weighted')\n",
    "dg=dendrogram(Z)\n",
    "X_re= X[:,dg['leaves']]#X_re reorder X by clustering\n",
    "\n",
    "X_corr_re=np.corrcoef(X_re, rowvar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = 0.996\n",
    "T = fcluster(Z, t=td, criterion='distance')\n",
    "# T=fcluster(Z, t=td, criterion='maxclust')\n",
    "T_re = T[dg['leaves']]\n",
    "\n",
    "plt.imshow(X_corr_re, aspect='auto', cmap=plt.cm.coolwarm, interpolation='nearest',origin='lower')\n",
    "plt.show()\n",
    "\n",
    "X_corr_label = np.zeros(X_corr_re.shape)\n",
    "for i in range(X_corr_re.shape[0]):\n",
    "    label_ind = np.where(T_re==T_re[i])[0]\n",
    "    X_corr_label[i,label_ind] = 1\n",
    "\n",
    "plt.imshow(X_corr_label, aspect='auto', cmap=plt.cm.gray, interpolation='nearest',origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigen gene is the value of first principal component of each community\n",
    "def eigen_gene(X_re,T_re):#return the weights of each gene in correponding eigen gene\n",
    "    eigen_X_w = []\n",
    "    pc = []\n",
    "    for i in np.unique(T_re):\n",
    "        pca=PCA(n_components=5).fit(X_re[:,T_re==i])\n",
    "        print(pca.explained_variance_ratio_)\n",
    "        pc.append(pca.transform(X_re[:,T_re==i]))\n",
    "        eigen_X_w.append(pca.components_.T)\n",
    "#         eigen_gene_size.append(np.where(T_re==i)[0].shape[0])\n",
    "    return np.array(pc),eigen_X_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_X,eigen_X_w=eigen_gene(X_re,T_re)\n",
    "eigen_dim=len(np.unique(T_re))\n",
    "print(eigen_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eigen = 1\n",
    "cell_eigen_X = eigen_X[0,:,:n_eigen]\n",
    "for i in range(eigen_dim-1):\n",
    "    cell_eigen_X = np.hstack((cell_eigen_X,eigen_X[i+1,:,:n_eigen]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "reset_seeds(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(cell_eigen_X.shape[1], 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,2*L),\n",
    ")\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.002, weight_decay=0.001)\n",
    "\n",
    "x_in=torch.tensor(cell_eigen_X.astype(np.float32))\n",
    "x_out=torch.tensor(latent_z.astype(np.float32))\n",
    "# Train the model\n",
    "for epoch in range(500):  # number of epochs\n",
    "    # Forward pass\n",
    "    output = model(x_in)\n",
    "    loss = loss_fn(output,x_out) \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss for each epoch\n",
    "    # print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Initialize a tensor to store the gradients\n",
    "pZ_pEg = np.zeros([cell_eigen_X.shape[0], L*2, cell_eigen_X.shape[1]])\n",
    "\n",
    "# Compute the gradients\n",
    "for i in range(cell_eigen_X.shape[0]):\n",
    "    x0=torch.tensor(cell_eigen_X[i,:].astype(np.float32),requires_grad=True)\n",
    "    z=model(x0)\n",
    "    for j in range(2*L):\n",
    "        x0.grad = None       \n",
    "        z[j].backward(retain_graph=True)\n",
    "        pZ_pEg[i,j,:] = x0.grad.detach()\n",
    "print(pZ_pEg.shape)\n",
    "print(loss_fn(model(x_in),x_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_gij = np.zeros((X.shape[0],eigen_dim*n_eigen,eigen_dim*n_eigen))\n",
    "for i in range(X.shape[0]):\n",
    "    eigen_gij[i] = pZ_pEg[i].T @ Fisher_g[i] @ pZ_pEg[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = np.zeros(Xs.shape)\n",
    "velo_standard = np.zeros(Xs.shape)\n",
    "velo = velo_pca@adata.varm['PCs'].T\n",
    "# velo = velo_pca@np.linalg.pinv(adata.varm['PCs'])\n",
    "for j in range(Xs.shape[1]):\n",
    "    X_mean = np.mean(Xs[:,j])\n",
    "    X_std = np.std(Xs[:,j])\n",
    "    X_standard[:,j] = (Xs[:,j]-X_mean)/X_std\n",
    "    velo_standard[:,j] = velo[:,j]/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_re = velo_standard[:,dg['leaves']]\n",
    "velo_eigen = np.zeros(cell_eigen_X.shape) # eigen gene 上的速度分量\n",
    "for i in range(eigen_dim):\n",
    "    velo_eigen[:,i*n_eigen:(i+1)*n_eigen] = velo_re[:,T_re==i+1]@eigen_X_w[i][:,:n_eigen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(eigen_dim):\n",
    "    Fisher_g_path = np.array([np.mean((smooth_func(eigen_gij[:,i,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.mean(smooth_func(np.abs(velo_eigen[:,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    \n",
    "    spline = UnivariateSpline(range(len(cell_arr)), Fisher_g_path, s=0.1)  \n",
    "    x_ls1 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls1 = spline(x_ls1)\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette2[0],s=10,alpha=alpha)\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), velo_pro_g_path, s=1)  \n",
    "    x_ls2 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls2 = spline(x_ls1)\n",
    "\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    ymin1 = min(y_ls1)\n",
    "    ymin1 = max([ymin1,0])\n",
    "    ymax1 = max(y_ls1)\n",
    "    plt.ylim(0,0.5)\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette2[1],s=10,alpha=alpha)\n",
    "    plt.yticks([])\n",
    "    ymin2 = min(y_ls2)\n",
    "    ymin2 = max([ymin2,0])\n",
    "    ymax2 = max(y_ls2)\n",
    "    plt.ylim(0,2.4)\n",
    "\n",
    "    plt.twinx()\n",
    "    ln1 = plt.plot(x_ls1, y_ls1, linewidth=4,color=palette1[0],label='$FI$')\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,0.5)\n",
    "\n",
    "    plt.twinx()\n",
    "    # # ln3 = plt.plot(x_ls3, y_ls3, linewidth=4,color=palette1[1],label='$g_{'+str(ei)+str(ej)+'}$')\n",
    "    ln2 = plt.plot(x_ls2, y_ls2, linewidth=4,color=palette1[1],label='$Velo$')\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(0,2.4)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_action_eigengene{i}.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **plot on eigengene eigen direction** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigen decompostion for Fisher_eigengene\n",
    "g_eig = [0]*X.shape[0]\n",
    "for i in range(X.shape[0]):\n",
    "    g_eig[i] = np.linalg.eigh(eigen_gij[i])\n",
    "\n",
    "gij_eig = np.array([g_eig[i][0] for i in range(X.shape[0])])\n",
    "gij_eig[np.where(gij_eig<0)] = 0\n",
    "velo_eig = np.abs(np.array([(velo_eigen[i]@g_eig[i][1]) for i in range(X.shape[0])]))\n",
    "zv1_eig = np.array([np.sqrt(velo_eig[i]**2*gij_eig[i]) for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_pro = np.zeros_like(velo_eig)\n",
    "eigen_values = np.zeros([X.shape[0],eigen_dim])\n",
    "for i in range(X.shape[0]):\n",
    "    velo_pro[i] = g_eig[i][1].T@velo_eig[i] # velocity projection on eigen vectors\n",
    "    eigen_values[i,:] = g_eig[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(eigen_dim):\n",
    "    Fisher_g_path = np.array([np.mean((smooth_func(eigen_values[:,-(i+1)]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.mean(smooth_func(np.abs(velo_pro[:,-(i+1)]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), Fisher_g_path, s=0.1)  \n",
    "    x_ls1 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls1 = spline(x_ls1)\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette2[0],s=10,alpha=alpha)\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), velo_pro_g_path, s=1)  \n",
    "    x_ls2 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls2 = spline(x_ls1)\n",
    "\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    ymin1 = min(y_ls1)\n",
    "    ymin1 = max([ymin1,0])\n",
    "    ymax1 = max(y_ls1)\n",
    "    plt.ylim(0,0.5)\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette2[1],s=10,alpha=alpha)\n",
    "    plt.yticks([])\n",
    "    ymin2 = min(y_ls2)\n",
    "    ymin2 = max([ymin2,0])\n",
    "    ymax2 = max(y_ls2)\n",
    "    plt.ylim(0,2)\n",
    "\n",
    "    plt.twinx()\n",
    "    ln1 = plt.plot(x_ls1, y_ls1, linewidth=4,color=palette1[0],label='$FI$')\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,0.5)\n",
    "\n",
    "    plt.twinx()\n",
    "    # # ln3 = plt.plot(x_ls3, y_ls3, linewidth=4,color=palette1[1],label='$g_{'+str(ei)+str(ej)+'}$')\n",
    "    ln2 = plt.plot(x_ls2, y_ls2, linewidth=4,color=palette1[1],label='$Velo$')\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(0,2)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_action_eigengene_eigendirection{i}.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **plot on hotspot** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hotspot\n",
    "# Create the Hotspot object and the neighborhood graph\n",
    "# hotspot works a lot faster with a csc matrix!\n",
    "hs = hotspot.Hotspot(\n",
    "    adata, \n",
    "    model='danb',\n",
    "    distances_obsp_key = 'distances'\n",
    ")\n",
    "\n",
    "hs.create_knn_graph(\n",
    "    weighted_graph=False, n_neighbors=k_nei,\n",
    ")\n",
    "\n",
    "hs_results = hs.compute_autocorrelations(jobs=1)\n",
    "\n",
    "# Select the genes with significant lineage autocorrelation\n",
    "hs_genes = hs_results.loc[hs_results.FDR < 0.1].sort_values('Z', ascending=False).head(800).index\n",
    "\n",
    "# Compute pair-wise local correlations between these genes\n",
    "lcz = hs.compute_local_correlations(hs_genes, jobs=1)\n",
    "\n",
    "modules = hs.create_modules(\n",
    "    min_gene_threshold=10, core_only=True, fdr_threshold=0.1\n",
    ")\n",
    "\n",
    "modules.value_counts()\n",
    "# np.save(result_path+'modules', modules.values)\n",
    "# np.save(result_path+'hs_genes', hs_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigen gene is the value of first principal component of each community\n",
    "def eigen_gene(X_re,T_re):#return the weights of each gene in correponding eigen gene\n",
    "    eigen_X_w = []\n",
    "    pc = []\n",
    "    for i in np.unique(T_re):\n",
    "        if i < 0:\n",
    "            continue\n",
    "        pca=PCA(n_components=2).fit(X_re[:,T_re==i])\n",
    "        print(pca.explained_variance_ratio_)\n",
    "        pc.append(pca.transform(X_re[:,T_re==i]))\n",
    "        eigen_X_w.append(pca.components_[0,:])\n",
    "#         eigen_gene_size.append(np.where(T_re==i)[0].shape[0])\n",
    "    return np.array(pc),eigen_X_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_hs = adata[:,hs_genes] # 只用hotspot有效的gene\n",
    "T_hs = np.array(hs.modules.tolist()) # 记录所有hs gene的module\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_hs = scaler.fit_transform(adata_hs.layers['Ms'])\n",
    "hs_X, hs_X_w = eigen_gene(X_hs,T_hs)\n",
    "hs_dim=len(hs_X_w)\n",
    "print(hs_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_hs_X=np.zeros((X_hs.shape[0],hs_dim))\n",
    "for j in range(X_hs.shape[0]):\n",
    "    for k in range(len(hs_X_w)):\n",
    "        cell_hs_X[j,k]=np.dot(hs_X_w[k],X_hs[j,T_hs==k+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seeds(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(cell_hs_X.shape[1], 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,2*L),\n",
    ")\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "x_in=torch.tensor(cell_hs_X.astype(np.float32))\n",
    "x_out=torch.tensor(latent_z.astype(np.float32))\n",
    "# Train the model\n",
    "for epoch in range(500):  # number of epochs\n",
    "    # Forward pass\n",
    "    output = model(x_in)\n",
    "    loss = loss_fn(output,x_out) \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss for each epoch\n",
    "#         print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Initialize a tensor to store the gradients\n",
    "pZ_phs = np.zeros([cell_hs_X.shape[0], L*2, cell_hs_X.shape[1]])\n",
    "\n",
    "# Compute the gradients\n",
    "for i in range(cell_hs_X.shape[0]):\n",
    "    x0=torch.tensor(cell_hs_X[i,:].astype(np.float32),requires_grad=True)\n",
    "    z=model(x0)\n",
    "    for j in range(2*L):\n",
    "        x0.grad = None       \n",
    "        z[j].backward(retain_graph=True)\n",
    "        pZ_phs[i,j,:] = x0.grad.detach()\n",
    "print(pZ_phs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher_hs = np.zeros((X.shape[0],hs_dim, hs_dim))\n",
    "for i in range(X.shape[0]):\n",
    "    Fisher_hs[i] = pZ_phs[i].T@Fisher_g[i]@pZ_phs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = np.zeros(adata_hs.layers['Ms'].shape)\n",
    "velo_standard = np.zeros(adata_hs.layers['Ms'].shape)\n",
    "velo = adata_hs.layers['velocity']\n",
    "# velo = velo_pca@np.linalg.pinv(adata.varm['PCs'])\n",
    "for j in range(adata_hs.layers['Ms'].shape[1]):\n",
    "    X_mean = np.mean(adata_hs.layers['Ms'][:,j])\n",
    "    X_std = np.std(adata_hs.layers['Ms'][:,j])\n",
    "    X_standard[:,j] = (adata_hs.layers['Ms'][:,j]-X_mean)/X_std\n",
    "    velo_standard[:,j] = velo[:,j]/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_re = velo_standard\n",
    "velo_eigen = np.zeros(cell_hs_X.shape) # hotspot gene 上的速度分量\n",
    "for i in range(hs_dim):\n",
    "    velo_eigen[:,i] = velo_re[:,T_hs==i+1]@hs_X_w[i][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(hs_dim):\n",
    "    Fisher_g_path = np.array([np.mean((smooth_func(Fisher_hs[:,i,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.mean(smooth_func(np.abs(velo_eigen[:,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), Fisher_g_path, s=0.1)  \n",
    "    x_ls1 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls1 = spline(x_ls1)\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette2[0],s=10,alpha=alpha)\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), velo_pro_g_path, s=1)  \n",
    "    x_ls2 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls2 = spline(x_ls1)\n",
    "\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    ymin1 = min(y_ls1)\n",
    "    ymin1 = max([ymin1,0])\n",
    "    ymax1 = max(y_ls1)\n",
    "    plt.ylim(0,0.1)\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette2[1],s=10,alpha=alpha)\n",
    "    plt.yticks([])\n",
    "    ymin2 = min(y_ls2)\n",
    "    ymin2 = max([ymin2,0])\n",
    "    ymax2 = max(y_ls2)\n",
    "    plt.ylim(0,12)\n",
    "\n",
    "    plt.twinx()\n",
    "    ln1 = plt.plot(x_ls1, y_ls1, linewidth=4,color=palette1[0],label='$FI$')\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,0.1)\n",
    "\n",
    "    plt.twinx()\n",
    "    # # ln3 = plt.plot(x_ls3, y_ls3, linewidth=4,color=palette1[1],label='$g_{'+str(ei)+str(ej)+'}$')\n",
    "    ln2 = plt.plot(x_ls2, y_ls2, linewidth=4,color=palette1[1],label='$Velo$')\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(0,12)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_action_hotspot{i}.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(hs_dim):\n",
    "    Fisher_g_path = np.array([np.mean((smooth_func(Fisher_hs[:,i,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.mean(smooth_func(np.abs(velo_eigen[:,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette1[0],s=20,alpha=alpha)\n",
    "    plt.ylim(0,0.11)\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette1[1],s=20,alpha=alpha)\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(0,15)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_action_hotspot{i}_scatter.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation of projected velocity!\n",
    "\n",
    "alpha = 1\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(hs_dim):\n",
    "    Fisher_g_path = np.array([np.mean((smooth_func(Fisher_hs[:,i,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.std(smooth_func(np.abs(velo_eigen[:,i]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette1[0],s=20,alpha=alpha)\n",
    "    plt.ylim(0,0.11)\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette1[1],s=20,alpha=alpha)\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_variation_hotspot{i}_scatter.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **plot on hotspot eigen direction** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_eig = [0]*X.shape[0]\n",
    "for i in range(X.shape[0]):\n",
    "    g_eig[i] = np.linalg.eigh(Fisher_hs[i])\n",
    "\n",
    "gij_eig = np.array([g_eig[i][0] for i in range(X.shape[0])])\n",
    "gij_eig[np.where(gij_eig<0)] = 0\n",
    "velo_eig = np.abs(np.array([(velo_eigen[i]@g_eig[i][1]) for i in range(X.shape[0])]))\n",
    "zv1_eig = np.array([np.sqrt(velo_eig[i]**2*gij_eig[i]) for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_pro = np.zeros_like(velo_eig)\n",
    "eigen_values = np.zeros([X.shape[0],hs_dim])\n",
    "for i in range(X.shape[0]):\n",
    "    velo_pro[i] = g_eig[i][1].T@velo_eig[i] # velocity projection on eigen vectors\n",
    "    eigen_values[i,:] = g_eig[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "frac = 0.01\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "palette1 = sns.color_palette('bright')\n",
    "palette2 = sns.color_palette('pastel')\n",
    "c1 = tuple((np.array(palette1[0])+np.array(palette1[-1]))/2)\n",
    "c2 = tuple((np.array(palette2[0])+np.array(palette2[-1]))/2)\n",
    "for i in range(hs_dim):\n",
    "    Fisher_g_path = np.array([np.mean((smooth_func(eigen_values[:,-(i+1)]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    velo_pro_g_path = np.array([np.mean(smooth_func(np.abs(velo_pro[:,-(i+1)]))[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), Fisher_g_path, s=0.1)  \n",
    "    x_ls1 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls1 = spline(x_ls1)\n",
    "    plt.scatter(np.array(range(len(cell_arr))), Fisher_g_path,c=palette2[0],s=10,alpha=alpha)\n",
    "    spline = UnivariateSpline(range(len(cell_arr)), velo_pro_g_path, s=1)  \n",
    "    x_ls2 = np.linspace(0, len(cell_arr), 100)\n",
    "    y_ls2 = spline(x_ls1)\n",
    "\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('Fisher Information',fontsize=20,weight='bold')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    ymin1 = min(y_ls1)\n",
    "    ymin1 = max([ymin1,0])\n",
    "    ymax1 = max(y_ls1)\n",
    "    plt.ylim(0,0.4)\n",
    "\n",
    "    plt.twinx()\n",
    "    plt.scatter(np.array(range(len(cell_arr))), velo_pro_g_path,c=palette2[1],s=10,alpha=alpha)\n",
    "    plt.yticks([])\n",
    "    ymin2 = min(y_ls2)\n",
    "    ymin2 = max([ymin2,0])\n",
    "    ymax2 = max(y_ls2)\n",
    "    plt.ylim(0,9)\n",
    "\n",
    "    plt.twinx()\n",
    "    ln1 = plt.plot(x_ls1, y_ls1, linewidth=4,color=palette1[0],label='$FI$')\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,0.4)\n",
    "\n",
    "    plt.twinx()\n",
    "    # # ln3 = plt.plot(x_ls3, y_ls3, linewidth=4,color=palette1[1],label='$g_{'+str(ei)+str(ej)+'}$')\n",
    "    ln2 = plt.plot(x_ls2, y_ls2, linewidth=4,color=palette1[1],label='$Velo$')\n",
    "    plt.ylabel('Velocity projection',fontsize=20,weight='bold')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(0,9)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color(palette1[0])\n",
    "    ax.spines['right'].set_color(palette1[1])\n",
    "    ax.spines['left'].set_linewidth(3)\n",
    "    ax.spines['right'].set_linewidth(3)\n",
    "    # plt.legend(handles=ln1+ln2,fontsize=15)\n",
    "    plt.savefig(figure_path+f'path_action_hotspot_eigendirection{i}.png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Curvature --> Transition point &&  Eigen spectrum** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.3\n",
    "crc_path = np.array([np.mean(crc_smooth[cell_arr[k]]) for k in range(len(cell_arr))])\n",
    "spline = UnivariateSpline(range(len(cell_arr)), crc_path, s=0.01)  \n",
    "x_ls1 = np.linspace(0, len(cell_arr), 100)\n",
    "y_ls1 = spline(x_ls1)\n",
    "plt.scatter(range(nearest_indices.shape[0]), crc_path,c=palette2[-1],s=10,alpha=alpha)\n",
    "\n",
    "\n",
    "plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "plt.ylabel('Curvature',fontsize=20,weight='bold')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "ymin1 = min(crc_path)\n",
    "ymax1 = max(crc_path)\n",
    "plt.ylim(ymin1,ymax1)\n",
    "\n",
    "plt.twinx()\n",
    "ln1 = plt.plot(x_ls1, y_ls1, linewidth=4,color=palette1[-1],label='$FI$')\n",
    "\n",
    "plt.yticks([])\n",
    "plt.ylim(ymin1,ymax1)\n",
    "plt.savefig(figure_path+f'path_curvature.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Fisher_g = Fisher_g[nearest_indices]\n",
    "for i in range(path_Fisher_g.shape[1]//2):\n",
    "    plt.scatter(np.array(range(path_Fisher_g.shape[0])),path_Fisher_g[:,i,i])\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('FI',fontsize=20,weight='bold')\n",
    "    plt.savefig(figure_path+f'path_fi.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "for i in range(path_Fisher_g.shape[1]//2):\n",
    "    plt.scatter(np.array(range(path_Fisher_g.shape[0])),np.log(path_Fisher_g[:,i,i]))\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('FI',fontsize=20,weight='bold')\n",
    "    plt.savefig(figure_path+f'path_log_fi.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "path_Fisher_hs = Fisher_hs[nearest_indices]\n",
    "for i in range(path_Fisher_hs.shape[1]):\n",
    "    plt.scatter(np.array(range(path_Fisher_hs.shape[0])),path_Fisher_hs[:,i,i], label=f'{i+1}')\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('FI Hotspot',fontsize=20,weight='bold')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path+f'path_fi_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "for i in range(path_Fisher_hs.shape[1]):\n",
    "    plt.scatter(np.array(range(path_Fisher_hs.shape[0])),np.log(path_Fisher_hs[:,i,i]), label=f'{i+1}')\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('log FI Hotspot',fontsize=20,weight='bold')\n",
    "plt.legend()    \n",
    "plt.savefig(figure_path+f'path_log_fi_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对DG，可以看到FI变化比较主要的是0，1，4，6，下面单独打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Fisher_hs = Fisher_hs[nearest_indices]\n",
    "for i in [0,1,4,6]:\n",
    "    plt.scatter(np.array(range(path_Fisher_hs.shape[0])),np.log(path_Fisher_hs[:,i,i]), label=f'{i+1}')\n",
    "    plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "    plt.ylabel('log FI Hotspot',fontsize=20,weight='bold')\n",
    "plt.legend(loc='lower right') \n",
    "plt.savefig(figure_path+f'path_log_fi_hotspot_selected.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['crc_smooth'] = crc_smooth\n",
    "module_scores = hs.calculate_module_scores()\n",
    "module_cols = ['crc_smooth']\n",
    "\n",
    "for c in [1,2,5,7]:\n",
    "    key = f\"Module {c}\"\n",
    "    adata.obs[key] = module_scores[c]\n",
    "    module_cols.append(key)\n",
    "\n",
    "fig = sc.pl.pca(adata, color=module_cols, frameon=False, return_fig=True)\n",
    "fig.savefig(figure_path+f'hotspot_module_score.png',dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_eig = [0]*path_Fisher_hs.shape[0]\n",
    "for i in range(path_Fisher_hs.shape[0]):\n",
    "    g_eig[i] = np.linalg.eigh(path_Fisher_hs[i])\n",
    "\n",
    "gij_eig = np.array([g_eig[i][0] for i in range(path_Fisher_hs.shape[0])])\n",
    "gij_eig[np.where(gij_eig<0)] = 0\n",
    "gij_eig = np.real(gij_eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(path_Fisher_hs.shape[1]):\n",
    "    plt.scatter(np.array(range(path_Fisher_hs.shape[0])),gij_eig[:,-(i+1)], label=f'{i+1}')\n",
    "plt.legend()\n",
    "plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "plt.ylabel('Eigenvalue Hotspot',fontsize=20,weight='bold')\n",
    "plt.savefig(figure_path+f'path_eigen_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "for i in range(path_Fisher_hs.shape[1]):\n",
    "    plt.scatter(np.array(range(path_Fisher_hs.shape[0])),np.log10(gij_eig[:,-(i+1)]), label=f'{i+1}')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "plt.ylabel('log Eigenvalue Hotspot',fontsize=16,weight='bold')\n",
    "plt.savefig(figure_path+f'path_log_eigen_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sensitivity** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted sensitivity\n",
    "\n",
    "for i in range(hs_dim):\n",
    "    sensitivity = np.zeros(path_Fisher_hs.shape[0])\n",
    "    for k in range(hs_dim):\n",
    "        sensitivity = sensitivity + np.array([np.abs(g_eig[j][1][i,k]) for j in range(path_Fisher_hs.shape[0])]) * np.array([g_eig[j][0][k] for j in range(path_Fisher_hs.shape[0])])\n",
    "    sensitivity = sensitivity/np.array([g_eig[j][0].sum() for j in range(path_Fisher_hs.shape[0])])\n",
    "    plt.plot(sensitivity,label=f'{i+1}')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "plt.ylabel('Module sensitivity',fontsize=20,weight='bold')\n",
    "plt.savefig(figure_path+f'path_sensitivity_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "for i in range(hs_dim):\n",
    "    plt.plot([np.abs(g_eig[j][1][i,-1]) for j in range(path_Fisher_hs.shape[0])],label=f'{i+1}')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "plt.ylabel('Module sensitivity',fontsize=20,weight='bold')\n",
    "plt.savefig(figure_path+f'path_weighted_sensitivity_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sparsity** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient(matrix):\n",
    "    # 将矩阵展平为一维数组\n",
    "    values = matrix.flatten()\n",
    "    \n",
    "    # 排序\n",
    "    sorted_values = np.sort(values)[::-1]\n",
    "    \n",
    "    # 计算 Gini 系数\n",
    "    n = len(sorted_values)\n",
    "    cumulative_values = np.cumsum(sorted_values)\n",
    "    gini = (2 * np.sum(cumulative_values) / np.sum(sorted_values) - (n + 1)) / n\n",
    "    \n",
    "    return gini\n",
    "\n",
    "# gini = [gini_coefficient(np.abs(Fisher_hs[i])) for i in range(Fisher_hs.shape[0])]\n",
    "plt.plot([gini_coefficient(np.abs(np.mean(Fisher_hs[cell_arr[k],:,:], axis=0))) for k in range(len(cell_arr))])\n",
    "plt.xlabel('Path',fontsize=20,weight='bold')\n",
    "plt.ylabel('FIM Gini',fontsize=20,weight='bold')\n",
    "plt.savefig(figure_path+f'path_Gini_hotspot.png',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gene module distribution** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 将数据组合成一个 DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "for i in [0,1,4,6]:\n",
    "    plt.subplot(2,1,1)\n",
    "    keys = range(len(cell_arr))\n",
    "    values = [X_hs[cell_arr[k],i] for k in range(len(cell_arr))]\n",
    "\n",
    "\n",
    "    # 绘制小提琴图\n",
    "\n",
    "    sns.violinplot(data=list(values), inner='quartile')\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('X')\n",
    "    plt.subplot(2,1,2)\n",
    "\n",
    "    plt.plot(np.log(np.array([np.mean((smooth_func(Fisher_hs[:,i,i]))[cell_arr[k]]) for k in range(len(cell_arr))])))\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('FI')\n",
    "    plt.savefig(result_path+f'X_FI {i+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,4,6]:\n",
    "    plt.subplot(2,1,1)\n",
    "    keys = range(len(cell_arr))\n",
    "    values = [X_hs[cell_arr[k],i] for k in range(len(cell_arr))]\n",
    "\n",
    "\n",
    "    # 绘制小提琴图\n",
    "\n",
    "    sns.violinplot(data=list(values), inner='quartile')\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('X')\n",
    "    plt.subplot(2,1,2)\n",
    "\n",
    "    plt.plot([np.abs(g_eig[j][1][i,-1]) for j in range(path_Fisher_hs.shape[0])],label=f'{i+1}')\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.savefig(result_path+f'X_sensitivity {i+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hs_dim):\n",
    "    plt.subplot(2,1,1)\n",
    "    keys = range(len(cell_arr))\n",
    "    values = [np.std(X_hs[cell_arr[k],i]) for k in range(len(cell_arr))]\n",
    "\n",
    "\n",
    "    # 绘制小提琴图\n",
    "\n",
    "    plt.plot(values)\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('Var(X)')\n",
    "    plt.subplot(2,1,2)\n",
    "\n",
    "    plt.plot([np.abs(g_eig[j][1][i,-1]) for j in range(path_Fisher_hs.shape[0])],label=f'{i+1}')\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.savefig(result_path+f'Xvar_sensitivity {i+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 将数据组合成一个 DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(Fisher_hs.shape[1]):\n",
    "    plt.subplot(2,1,1)\n",
    "    keys = range(len(cell_arr))\n",
    "    values = [(np.abs(smooth_func(Fisher_hs[:,i,i]))+1e-5)[cell_arr[k]] for k in range(len(cell_arr))]\n",
    "\n",
    "\n",
    "    # 绘制小提琴图\n",
    "\n",
    "    # sns.violinplot(data=list(values), inner='quartile', showfliers=False)\n",
    "    sns.boxplot(data=list(values), showfliers=False)\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('FI')\n",
    "    plt.yscale('log')\n",
    "    plt.subplot(2,1,2)\n",
    "\n",
    "    plt.plot([np.abs(g_eig[j][1][i,-1]) for j in range(path_Fisher_hs.shape[0])],label=f'{i+1}')\n",
    "\n",
    "    plt.xlabel('Path')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.savefig(result_path+f'FI_sensitivity {i+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 70))\n",
    "\n",
    "for k in range(len(cell_arr)):\n",
    "    plt.subplot(7, 4, k + 1)\n",
    "    values = [np.log((np.abs(smooth_func(Fisher_hs[:, i, i])) + 1e-5)[cell_arr[k]]) for i in range(Fisher_hs.shape[1])]\n",
    "    \n",
    "    for i in range(Fisher_hs.shape[1]):\n",
    "        sns.kdeplot(values[i], fill=False, label=f'{i + 1}', alpha=0.5)\n",
    "    \n",
    "    plt.ylabel('Density', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('log Fisher Information', fontsize=14, fontweight='bold')\n",
    "    plt.title(f'Cluster {k + 1}', fontsize=14, fontweight='bold')\n",
    "    plt.xlim(-9, -2)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(fontsize=12, borderpad=1.5)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "plt.savefig(result_path+f'per cluster.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# 假设 cell_arr 和 Fisher_hs 已经定义\n",
    "colors = plt.get_cmap('Spectral')(np.linspace(0, 1, len(cell_arr)))  # 使用 spectral 颜色映射\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "plt.figure(figsize=(30, 20))\n",
    "\n",
    "for i in range(Fisher_hs.shape[1]):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    color_labels = []\n",
    "\n",
    "    values = [np.log((np.abs(smooth_func(Fisher_hs[:, i, i])) + 1e-5)[cell_arr[k]]) for k in range(len(cell_arr))]\n",
    "    \n",
    "    for k in range(len(cell_arr)):\n",
    "        sns.kdeplot(values[k], fill=False, label=f'{k + 1}', alpha=0.5, color=colors[k, :])\n",
    "        color_labels.append(f'Cluster {k + 1}')\n",
    "\n",
    "    plt.ylabel('Density', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('log Fisher Information', fontsize=14, fontweight='bold')\n",
    "    plt.title(f'Hotspot {i + 1}', fontsize=14, fontweight='bold')\n",
    "    plt.xlim(-9, -2)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    norm = Normalize(vmin=0, vmax=len(cell_arr) - 1)  # 设置归一化范围\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # 需要设置一个空数组\n",
    "\n",
    "    # 添加 colorbar 仅标记开始和结束\n",
    "    cbar = plt.colorbar(sm, ticks=[0, len(cell_arr) - 1])\n",
    "    cbar.ax.set_yticklabels([f'Cluster 1', f'Cluster {len(cell_arr)}'], fontsize=12)  # 设置 colorbar 标签\n",
    "\n",
    "    patches = [Patch(color=colors[k, :], label=f'Class {k + 1}') for k in range(len(cell_arr))]\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.savefig(result_path+f'per dim.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Back to gene expression space** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------use a simple neural network to study dmu/dt and dsigma/dt\n",
    "latent_z = np.hstack((mu_learned,sigma_learned))\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,2*L),\n",
    ")\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "x_in=torch.tensor(X.astype(np.float32))\n",
    "x_out=torch.tensor(latent_z.astype(np.float32))\n",
    "# Train the model\n",
    "for epoch in range(200):  # number of epochs\n",
    "    # Forward pass\n",
    "    output = model(x_in)\n",
    "    loss = loss_fn(output,x_out) \n",
    "#     if epoch% 10 == 9:\n",
    "#         print(epoch,loss)\n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "pZ_pGE = np.zeros([X.shape[0], L*2, X.shape[1]])\n",
    "\n",
    "# Compute the gradients\n",
    "for i in range(X.shape[0]):\n",
    "    x0=torch.tensor(X[i,:],requires_grad=True)\n",
    "    z=model(x0)\n",
    "    for j in range(2*L):\n",
    "        x0.grad = None       \n",
    "        z[j].backward(retain_graph=True)\n",
    "        pZ_pGE[i,j,:] = x0.grad.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher_X = np.zeros((X.shape[0],X.shape[1]))\n",
    "for i in range(X.shape[0]):\n",
    "    Fisher_X[i] = np.diag(pZ_pGE[i].T@Fisher_g[i]@pZ_pGE[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Fisher_X = np.log(Fisher_X)\n",
    "np.mean(log_Fisher_X),np.median(log_Fisher_X),np.max(log_Fisher_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stiff_ratio = []\n",
    "stiff_scales = []\n",
    "for k in range(len(cell_arr)):\n",
    "    fis = log_Fisher_X[cell_arr[k],:]\n",
    "    cnt = 0\n",
    "    stiff_scale = 0\n",
    "    for i in range(fis.shape[0]):\n",
    "        cnt += np.mean(fis[i,:] > np.max(fis[i,:]) - 1)\n",
    "        stiff_scale += np.max(fis[i,:])\n",
    "    \n",
    "    stiff_scale /= fis.shape[0]\n",
    "    cnt /= fis.shape[0]\n",
    "    stiff_ratio.append(cnt)\n",
    "    stiff_scales.append(stiff_scale)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1,len(cell_arr)+1), stiff_ratio, label = 'stiff ratio')\n",
    "plt.xlabel('Clusters', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Stiff Ratio', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1,len(cell_arr)+1), stiff_scales, label = 'stiff scale')\n",
    "plt.xlabel('Clusters', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Stiff Scale', fontsize=14, fontweight='bold')\n",
    "\n",
    "# plt.savefig(result_path+f'stiff statistic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 cell_arr 和 log_Fisher_X 已经定义并且有数据\n",
    "stiff_ratio = []\n",
    "stiff_scales = []\n",
    "for k in range(len(cell_arr)):\n",
    "    fis = log_Fisher_X[cell_arr[k], :]\n",
    "    cnt = 0\n",
    "    stiff_scale = 0\n",
    "    for i in range(fis.shape[0]):\n",
    "        cnt += np.mean(fis[i, :] > np.max(fis[i, :]) - 1)\n",
    "        stiff_scale += np.max(fis[i, :])  # 修正索引，确保是 fis[i, :] 而不是 fis[1, :]\n",
    "\n",
    "    stiff_scale /= fis.shape[0]\n",
    "    cnt /= fis.shape[0]\n",
    "    stiff_ratio.append(cnt)\n",
    "    stiff_scales.append(stiff_scale)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 创建第一个 y 轴\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Clusters', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Stiff Ratio', fontsize=14, fontweight='bold', color='blue')\n",
    "ax1.plot(range(1,len(cell_arr)+1), stiff_ratio, label='Stiff Ratio', color='blue', linewidth=2)\n",
    "ax1.tick_params(axis='y', labelcolor='blue', size=12)\n",
    "\n",
    "# 创建第二个 y 轴\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Stiff Scale', fontsize=14, fontweight='bold', color='orange')\n",
    "ax2.plot(range(1,len(cell_arr)+1), stiff_scales, label='Stiff Scale', color='orange', linewidth=2)\n",
    "ax2.tick_params(axis='y', labelcolor='orange', size=12)\n",
    "\n",
    "# 添加图例\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Stiff Ratio and Stiff Scale', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(result_path + 'stiff_statistic.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check gene module1，2，5，7** ##\n",
    "Mki67,Cdk1,Birc5,Prdx4,Aurka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(modules.keys().tolist())[np.array(modules.tolist()) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(modules.keys().tolist())[np.array(modules.tolist()) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(modules.keys().tolist())[np.array(modules.tolist()) == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(modules.keys().tolist())[np.array(modules.tolist()) == 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5，7中有一些齿状回发生的关键基因** ##\n",
    "Bdnf (Brain-Derived Neurotrophic Factor): BDNF 是神经元生长和存活的重要调控因子，已知在海马的神经发生中发挥重要作用。\n",
    "\n",
    "Grin2b (Glutamate Receptor, Ionotropic, NMDA 2B): NMDA 受体在突触可塑性和学习记忆中起着关键作用，影响神经发生。\n",
    "\n",
    "Negr1 (Neuron-Glial Related 1): 该基因在神经元的发育和功能中发挥作用，可能与齿状回的形成有关。\n",
    "\n",
    "Ntrk3 (Neurotrophic Receptor Tyrosine Kinase 3): 该基因编码的受体在神经元的生长和分化中起着重要作用，可能影响齿状回的发育。\n",
    "\n",
    "Syt1 (Synaptotagmin 1): 与突触传递相关，可能在神经发生过程中发挥作用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
